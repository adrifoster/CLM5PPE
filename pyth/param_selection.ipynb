{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d023b9-81d4-4a50-bc7d-6b198b171c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cftime\n",
    "import dask\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cac7a58-ef33-49e4-9f3d-cca6c7f97f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated for PBS scheduler\n",
    "# this could go into utils.\n",
    "# By default gets 1 core w/ 25 GB memory\n",
    "def get_ClusterClient(ncores=1, nmem='25GB'):\n",
    "    import dask\n",
    "    from dask_jobqueue import PBSCluster\n",
    "    from dask.distributed import Client\n",
    "    ncores=ncores\n",
    "    nmem = nmem\n",
    "\n",
    "    cluster = PBSCluster(\n",
    "        cores=ncores, # The number of cores you want\n",
    "        memory=nmem, # Amount of memory\n",
    "        processes=ncores, # How many processes\n",
    "        queue='casper', # The type of queue to utilize (/glade/u/apps/dav/opt/usr/bin/execcasper)\n",
    "        resource_spec='select=1:ncpus='+str(ncores)+':mem='+nmem, # Specify resources\n",
    "        project='P93300641', # Input your project ID here\n",
    "        walltime='4:00:00', # Amount of wall time\n",
    "        interface='ib0', # Interface to use\n",
    "    )\n",
    "\n",
    "    client = Client(cluster)\n",
    "    return cluster, client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2aae54-4033-4045-9998-739faa063800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/djk2120/miniconda3/envs/lens-py/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 38692 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    }
   ],
   "source": [
    "cluster, client = get_ClusterClient()\n",
    "cluster.scale(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4a6b65d3-1703-45cb-be4c-f344edb24dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.12.206.54:35426</li>\n",
       "  <li><b>Dashboard: </b><a href='https://https://jupyterhub.hpc.ucar.edu/stable/user/djk2120/proxy/{port}/status' target='_blank'>https://https://jupyterhub.hpc.ucar.edu/stable/user/djk2120/proxy/{port}/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>20</li>\n",
       "  <li><b>Cores: </b>20</li>\n",
       "  <li><b>Memory: </b>500.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.12.206.54:35426' processes=20 threads=20, memory=500.00 GB>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180d6d02-828b-4a11-bcd4-4c1c9f72b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(keys,paramkey):\n",
    "    params=[]\n",
    "    minmaxs=[]\n",
    "    for key in keys:\n",
    "        ix     = paramkey.key==key\n",
    "        params.append(paramkey.param[ix].values[0])\n",
    "        minmaxs.append(paramkey.minmax[ix].values[0])\n",
    "    return params,minmaxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919d7419-c832-43f2-abf2-0828984b5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_wts(nyears):\n",
    "    days_pm  = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "    return xr.DataArray(np.tile(days_pm,nyears),dims='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "db373501-870f-491b-a4fd-dac8833e3490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble(name,data_vars,htape,keys,paramkey):\n",
    "    '''\n",
    "    Returns a dataset comprising the given ensemble\n",
    "    name  = 'CTL2020' or 'C285' or 'AF1905'\n",
    "    data_vars, e.g. ['GPP','HR','AR']\n",
    "    htape, e.g. 'h0' 0/1/2/3/4/5/7 available\n",
    "    '''\n",
    "    \n",
    "    #define the directory structure and find files\n",
    "    topdir     = '/glade/scratch/djk2120/PPEn11/hist/' \n",
    "    thisdir    = topdir+name+'/'\n",
    "    files      = [glob.glob(thisdir+'*'+key+'*'+htape+'*.nc')[0] for key in keys]\n",
    "\n",
    "    def preprocess(ds):\n",
    "        return ds[data_vars]\n",
    "\n",
    "    #read in the dataset\n",
    "    ds = xr.open_mfdataset(files,combine='nested',concat_dim='ens',\n",
    "                           parallel=True,preprocess=preprocess)\n",
    "\n",
    "    #fix up time dimension\n",
    "    ds['time'] = xr.cftime_range(str(2005),periods=120,freq='MS') #fix time bug\n",
    "    \n",
    "    #add in some extra variables\n",
    "    ds0 = xr.open_dataset(files[0])\n",
    "    extras = ['grid1d_lat','grid1d_lon']\n",
    "    for extra in extras:\n",
    "        ds[extra]=ds0[extra]\n",
    "\n",
    "    #append some info about key/param/minmax\n",
    "    params,minmaxs = get_params(keys,paramkey) \n",
    "    ds['key']    = xr.DataArray(keys,dims='ens')\n",
    "    ds['param']  = xr.DataArray(params,dims='ens')\n",
    "    ds['minmax'] = xr.DataArray(minmaxs,dims='ens')\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e3d1934f-95a6-4ae4-b1a8-9b740539890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24353014-5b81-4867-945c-a41c126dbb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch the paraminfo\n",
    "csv = '/glade/scratch/djk2120/PPEn11/firstpass.csv' \n",
    "paramkey = pd.read_csv(csv)\n",
    "\n",
    "#fetch the sparsegrid landarea\n",
    "la_file = '/glade/scratch/djk2120/PPEn08/sparsegrid_landarea.nc'\n",
    "la = xr.open_dataset(la_file).landarea  #km2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316c2b7b-ff7f-45b6-a3d3-611c0b0dc0d7",
   "metadata": {},
   "source": [
    "### CTL2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "88c35d4c-46ef-429b-a76e-c3aed43e83bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose your subset of variables\n",
    "data_vars = ['GPP','AR','HR','EFLX_LH_TOT','FCTR','FAREA_BURNED',\n",
    "             'TWS','SOILWATER_10CM','SNOWDP','TV','TSOI_10CM','TLAI','FSR']\n",
    "keys = paramkey.key\n",
    "#read in the dataset\n",
    "ds = get_ensemble('CTL2010',data_vars,'h0',keys,paramkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d896df7-de87-4d03-8de9-33aefba940ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = np.unique(ds.param)\n",
    "ix = uniques=='default'\n",
    "uniques = uniques[~ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7c732e27-c66c-466f-964c-30a14dbe337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pair(da,params,p):\n",
    "    ix = params==p\n",
    "    if ix.sum().values<2:\n",
    "        ix = np.logical_or(ix,params=='default')\n",
    "    return da.isel(ens=ix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "60068a3c-ad57-4739-a10e-609aa4e32ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_effect(pair):\n",
    "    delt  = pair.isel(ens=0)-pair.isel(ens=1)\n",
    "    sigma = np.std(delt.mean(dim='year'))\n",
    "    if sigma>0:\n",
    "        pe_mean = abs((la*delt).sum(dim='gridcell').mean(dim='year').values)\n",
    "        iav     = (la*pair).sum(dim='gridcell').std(dim='year').values\n",
    "        pe_iav  = abs(iav[0]-iav[1])\n",
    "    else:\n",
    "        pe_mean = 0\n",
    "        pe_iav  = 0\n",
    "\n",
    "    \n",
    "    return pe_mean,pe_iav\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a8a25-449f-4b42-8459-96f719917c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_effect2(pair1,pair2):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3e82c717-c912-4b7c-91d8-89a155bba54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial(da,params,uniques):\n",
    "    #lower scores have more distinct spatial signature\n",
    "    nx = len(uniques)\n",
    "    \n",
    "    #calculate delta annual mean for each param-pair\n",
    "    delts = np.ndarray([nx,400])\n",
    "    for i,u in zip(range(nx),uniques):\n",
    "        pair = find_pair(da,params,u).mean(dim='year')\n",
    "        delt = pair.isel(ens=0) - pair.isel(ens=1)\n",
    "        delts[i,:] = delt\n",
    "        \n",
    "    #calculate cross-correlations\n",
    "    #  skip calc if sigma==0\n",
    "    sigs = np.std(delts,axis=1)\n",
    "    rvals = np.zeros([nx,nx])\n",
    "    for i in range(nx):\n",
    "        if sigs[i]==0:\n",
    "            rvals[i,:]=1\n",
    "        else:\n",
    "            for j in range(i,nx,1):\n",
    "                if sigs[j]==0:\n",
    "                    rvals[i,j] = 1\n",
    "                elif i==j:\n",
    "                    rvals[i,j] = 1\n",
    "                else:\n",
    "                    x=delts[[i,j],:]\n",
    "                    r2= np.corrcoef(x)[0,1]**2\n",
    "                    rvals[i,j] =r2\n",
    "                    rvals[j,i] =r2\n",
    "                    \n",
    "    return rvals.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ecf4a4be-2f52-4417-ac31-d920a4c24ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPP\n",
      "AR\n",
      "HR\n",
      "EFLX_LH_TOT\n",
      "FCTR\n",
      "FAREA_BURNED\n",
      "TWS\n",
      "SOILWATER_10CM\n",
      "SNOWDP\n",
      "TV\n",
      "TSOI_10CM\n",
      "TLAI\n",
      "FSR\n"
     ]
    }
   ],
   "source": [
    "pes=dict()\n",
    "for datavar in data_vars:\n",
    "    print(datavar)\n",
    "    da = (month_wts(10)*ds[datavar]).groupby('time.year').sum().compute()\n",
    "    s1 = []; s2 = []\n",
    "    for u in uniques:\n",
    "        pair = find_pair(da,ds.param,u)\n",
    "        m,i  = param_effect(pair)\n",
    "        s1.append(m)\n",
    "        s2.append(i)\n",
    "    s3 = spatial(da,ds.param,uniques)\n",
    "    pes[datavar]={'s1':s1,'s2':s2,'s3':s3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "11f7985f-c642-4663-85fe-11f51eee0c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPP s1 lmrhd\n",
      "GPP s1 kmax\n",
      "GPP s1 medlynintercept\n",
      "GPP s1 jmaxb0\n",
      "GPP s1 lmrse\n",
      "GPP s2 wc2wjb0\n",
      "GPP s2 leafcn\n",
      "GPP s2 sucsat_sf\n",
      "GPP s3 aq_sp_yield_min\n",
      "AR s1 vcmaxse_sf\n",
      "HR s2 FUN_fracfixers\n",
      "HR s3 occur_hi_gdp_tree\n",
      "EFLX_LH_TOT s1 medlynslope\n",
      "EFLX_LH_TOT s2 fff\n",
      "EFLX_LH_TOT s2 frac_sat_soil_dsl_init\n",
      "FCTR s3 non_boreal_peatfire_c\n",
      "FAREA_BURNED s1 jmaxse_sf\n",
      "TWS s1 hksat_sf\n",
      "TWS s1 bsw_sf\n",
      "TWS s1 watsat_sf\n",
      "TWS s2 baseflow_scalar\n",
      "SNOWDP s1 ceta\n",
      "SNOWDP s1 snw_rds_refrz\n",
      "SNOWDP s1 zsno\n",
      "SNOWDP s1 zetamaxstable\n",
      "SNOWDP s1 upplim_destruct_metamorph\n",
      "SNOWDP s2 wind_snowcompact_fact\n",
      "SNOWDP s3 cropfire_a1\n",
      "TV s2 kcha\n",
      "TV s2 nstem\n",
      "TLAI s2 theta_cj\n",
      "FSR s1 rhosnir\n",
      "FSR s1 rholnir\n",
      "FSR s1 taulnir\n"
     ]
    }
   ],
   "source": [
    "top50 = []\n",
    "for datavar in data_vars:\n",
    "    cats  = ['s1','s2','s3']\n",
    "    nxs   = [5,3,1]\n",
    "    flips = [False,False,True]\n",
    "    for cat,nx,flip in zip(cats,nxs,flips):\n",
    "        s = pes[datavar][cat]\n",
    "        ranks = np.argsort(s)   \n",
    "        if flip:\n",
    "            ranks = np.flipud(ranks)\n",
    "        for i in ranks[-nx:]:\n",
    "            u = uniques[i]\n",
    "            if u not in top50:\n",
    "                print(datavar,cat,u)\n",
    "                top50.append(u)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "477a90e5-812e-4871-adc9-7e1554f151d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lmrhd',\n",
       " 'kmax',\n",
       " 'medlynintercept',\n",
       " 'jmaxb0',\n",
       " 'lmrse',\n",
       " 'wc2wjb0',\n",
       " 'leafcn',\n",
       " 'sucsat_sf',\n",
       " 'aq_sp_yield_min',\n",
       " 'vcmaxse_sf',\n",
       " 'FUN_fracfixers',\n",
       " 'occur_hi_gdp_tree',\n",
       " 'medlynslope',\n",
       " 'fff',\n",
       " 'frac_sat_soil_dsl_init',\n",
       " 'non_boreal_peatfire_c',\n",
       " 'jmaxse_sf',\n",
       " 'hksat_sf',\n",
       " 'bsw_sf',\n",
       " 'watsat_sf',\n",
       " 'baseflow_scalar',\n",
       " 'ceta',\n",
       " 'snw_rds_refrz',\n",
       " 'zsno',\n",
       " 'zetamaxstable',\n",
       " 'upplim_destruct_metamorph',\n",
       " 'wind_snowcompact_fact',\n",
       " 'cropfire_a1',\n",
       " 'kcha',\n",
       " 'nstem',\n",
       " 'theta_cj',\n",
       " 'rhosnir',\n",
       " 'rholnir',\n",
       " 'taulnir']"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6f23587c-c61c-46a2-bdc8-3190ce5ff357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "30a8856e-06d3-4e96-9626-c5b39b428b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose your subset of variables\n",
    "data_vars = ['GPP','AR','HR','EFLX_LH_TOT','FCTR','FAREA_BURNED',\n",
    "             'TWS','SOILWATER_10CM','SNOWDP','TV','TSOI_10CM','TLAI','FSR']\n",
    "keys = paramkey.key\n",
    "#read in the dataset\n",
    "c285 = get_ensemble('C285',data_vars,'h0',keys,paramkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "788b7aa0-14a1-4a94-9368-7392168b14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datavar = 'GPP'\n",
    "s4 = []\n",
    "da1 = (month_wts(10)*c285[datavar]).groupby('time.year').sum().compute()\n",
    "da2 = (month_wts(10)*ds[datavar]).groupby('time.year').sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "3f860c53-424a-4442-b426-92b09c4bb6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "s4=[]\n",
    "for u in uniques:\n",
    "\n",
    "    pair1 = find_pair(da1,ds.param,u)\n",
    "    pair2 = find_pair(da2,ds.param,u)\n",
    "\n",
    "    x1=(la*pair1).sum(dim='gridcell').mean(dim='year')\n",
    "    x2=(la*pair2).sum(dim='gridcell').mean(dim='year')\n",
    "    fx = (x1/x2).values\n",
    "    dx = abs(fx[1]-fx[0])\n",
    "\n",
    "    s4.append(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "fc57b2f4-0da9-4219-b271-e2b5703f557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmrhd\n",
      "vcmaxha\n",
      "wc2wjb0\n",
      "medlynintercept\n",
      "jmaxb0\n"
     ]
    }
   ],
   "source": [
    "ranks = np.argsort(s4)\n",
    "for i in ranks[-5:]:\n",
    "    u = uniques[i]\n",
    "    print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaca7f54-440f-4744-8ceb-ffb444030bf9",
   "metadata": {},
   "source": [
    "### C285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd6168-d0b2-4ba9-ade8-468e35f022bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-lens-py]",
   "language": "python",
   "name": "conda-env-miniconda3-lens-py-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
