{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pyDOE import *\n",
    "import xarray as xr\n",
    "import copy\n",
    "import netCDF4\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download latest version of params file from google drive\n",
    "* requires 'publishing' the google drive spreadsheet\n",
    "* file > publish to web\n",
    "* then it can be set up to continuously publish the spreadsheet to a stable url (with some latency, maybe 1-2 minutes)\n",
    "* note that the first tab must be the sheet where the relevant information is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQs413GtLXtHVDCqEPgAwn4BbDjoWmV7uFqOAWH4mgpxXoVfN6ijnJdhyRgLkV-n2eU-sSQush4CzYU/pub?output=csv'\n",
    "cmd = 'curl -L '+data_url+' > params.csv' # need to add -L option to force redirects\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a class for organizing parameter information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamInfo(object):\n",
    "    \"\"\"\n",
    "    Stores parameter information.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, loc, minval=None, maxval=None, defval=None, value=None):\n",
    "        self._name = name # parameter name\n",
    "        self._min = minval # minimum value\n",
    "        self._max = maxval # maximum value\n",
    "        self._default = defval # default value\n",
    "        self._value = value # actual value to be used in a given ensemble member\n",
    "        self._location = loc # location of parameter (params file or namelist)\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def min(self):\n",
    "        return self._min\n",
    "\n",
    "    @property\n",
    "    def max(self):\n",
    "        return self._max\n",
    "    \n",
    "    @property\n",
    "    def default(self):\n",
    "        return self._default\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        return self._value\n",
    "    \n",
    "    @property\n",
    "    def location(self):\n",
    "        return self._location\n",
    "    \n",
    "    @name.setter\n",
    "    def name(self, new_name):\n",
    "        self._name = new_name\n",
    "   \n",
    "    @min.setter\n",
    "    def min(self, new_min):\n",
    "        self._min = new_min\n",
    "        \n",
    "    @max.setter\n",
    "    def max(self, new_max):\n",
    "        self._max = new_max\n",
    "        \n",
    "    @default.setter\n",
    "    def default(self, new_def):\n",
    "        self._default = new_def\n",
    "        \n",
    "    @value.setter\n",
    "    def value(self, new_val):\n",
    "        self._value = new_val\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"%s:\\n\\tloc = %s\\n\\tdefault = %s\\n\\tmin = %s\\n\\tmax = %s\\n\\tvalue = %s\" % (self.name, self.location, self.default, self.min, self.max, self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: add these or other unit tests to ParamInfo class itself\n",
    "# Check every time the code updates, or adding new functionality\n",
    "\n",
    "# testing out the class/dictionary functionality\n",
    "test_dict = {\"P1\": ParamInfo(\"P1\", minval=0.0, maxval=1.0, defval=2.0, loc='N'),\n",
    "             \"P2\": ParamInfo(\"P2\", minval=[0,0,0,0,0], maxval=[100,100,100,100,100], defval=[0,1,2,3,4], loc='P'),\n",
    "             \"P3\": ParamInfo(\"P3\", minval=\"min\", maxval=\"max\", defval=\"value\", loc='N'),\n",
    "             \"P4\": ParamInfo(\"P4\", loc='P')\n",
    "            }\n",
    "\n",
    "# example of adding a new parameter\n",
    "test_dict[\"new_param\"] = ParamInfo(\"new_param\", 'N')\n",
    "\n",
    "# example of setting the max value\n",
    "test_dict[\"P4\"].max = 200\n",
    "\n",
    "# example of setting the value for a given ensemble member\n",
    "test_dict[\"new_param\"].value = 100\n",
    "\n",
    "# look at the test dictionary\n",
    "for key in test_dict:\n",
    "    print(test_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a class for organizing ensemble members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Member(object):\n",
    "    \"\"\"\n",
    "    Stores and works with a bunch of ParamInfos.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, paraminfo):\n",
    "        self._name = name\n",
    "        self._paraminfo = paraminfo\n",
    "        \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def paraminfo(self):\n",
    "        return self._paraminfo\n",
    "    \n",
    "    @name.setter\n",
    "    def name(self, new_name):\n",
    "        self._name = new_name\n",
    "    \n",
    "    def get_names(self):\n",
    "        \"\"\"\n",
    "        Returns a list of parameter names.\n",
    "        \"\"\"\n",
    "        \n",
    "        names = []\n",
    "        for param in self._paraminfo:\n",
    "            names.append(self._paraminfo[param].name)\n",
    "        return names\n",
    "                 \n",
    "    def write(self, sampling_protocol):\n",
    "        \"\"\"\n",
    "        Writes files to disk for each member: param netcdf, namelist mods txt.\n",
    "        \"\"\"\n",
    "        \n",
    "        # TO DO: remove existing files from these folders before writing output?\n",
    "        \n",
    "        # generate file names based on member name\n",
    "        i = int(self._name)\n",
    "        self._pftfile = \"../paramfiles/\"+sampling_protocol+str(i+1).zfill(4)+\".nc\"\n",
    "        self._nlfile = \"../namelist_mods/\"+sampling_protocol+str(i+1).zfill(4)+\".txt\" \n",
    "        \n",
    "        # assign the basepftfile (this also happens in Ensemble class)\n",
    "        #self._basepftfile = \"../basecase/clm5_params.c200717.nc\"\n",
    "        self._basepftfile= '/glade/p/cgd/tss/people/oleson/modify_param/ctsm51_params.c210217_kwo.c210222.nc'\n",
    "        \n",
    "        # create the pftfile as a copy of the basepftfile\n",
    "        # note this will create a file for each ensemble member, regardless of if param mods are needed\n",
    "        cmd = 'cp '+self._basepftfile+' '+self._pftfile\n",
    "        os.system(cmd)\n",
    "        \n",
    "        # create the nlfile\n",
    "        # note this will create a file for each ensemble member, regardless of if nl mods are needed\n",
    "        with open(self._nlfile,\"w\") as file:\n",
    "            output = \"! user_nl_clm namelist options written by generate_params:\\n\"\n",
    "            file.write(output)\n",
    "            \n",
    "        # read in the pftfile using netCDF4 package\n",
    "        dset = netCDF4.Dataset(self._pftfile,'r+')\n",
    "        \n",
    "        # modify the param/nl files\n",
    "        if sampling_protocol == \"OAAT\":\n",
    "            for paramname in self.get_names():\n",
    "                \n",
    "                # TO DO: code these flags more universally?\n",
    "                # CWD flag \n",
    "                if paramname == ['cwd_fcel', 'cwd_flig']: \n",
    "                    # only modify if list is not empty\n",
    "                    if self._paraminfo['CWD'].value:\n",
    "                        # loop over parameters\n",
    "                        for i in np.arange(len(paramname)):\n",
    "                            print(paramname[i]+' modified in '+self._pftfile)\n",
    "                            dset[paramname[i]][:] = self._paraminfo['CWD'].value[i]\n",
    "                                \n",
    "                # Q10 flag\n",
    "                elif paramname == ['q10_hr', 'froz_q10']: \n",
    "                    # only modify if list is not empty\n",
    "                    if self._paraminfo['Q10'].value:\n",
    "                        # loop over parameters\n",
    "                        for i in np.arange(len(paramname)):\n",
    "                            print(paramname[i]+' modified in '+self._pftfile)\n",
    "                            dset[paramname[i]][:] = self._paraminfo['Q10'].value[i]\n",
    "                \n",
    "                # LF flag\n",
    "                elif paramname == ['lf_fcel', 'lf_flab', 'lf_flig']:\n",
    "                    # only modify if list is not empty\n",
    "                    if self._paraminfo['LF'].value:\n",
    "                        # loop over parameters\n",
    "                        for i in np.arange(len(paramname)):\n",
    "                            print(paramname[i]+' modified in '+self._pftfile)\n",
    "                            dset[paramname[i]][:] = self._paraminfo['LF'].value[i]\n",
    "                \n",
    "                # FR flag\n",
    "                elif paramname == ['fr_fcel', 'fr_flab', 'fr_flig']:\n",
    "                    # only modify if list is not empty\n",
    "                    if self._paraminfo['FR'].value:\n",
    "                        # loop over parameters\n",
    "                        for i in np.arange(len(paramname)):\n",
    "                            print(paramname[i]+' modified in '+self._pftfile)\n",
    "                            dset[paramname[i]][:] = self._paraminfo['FR'].value[i]\n",
    "                            \n",
    "                # KCN flag\n",
    "                elif paramname == ['kc_nonmyc', 'kn_nonmyc', 'akc_active', 'akn_active', 'ekc_active', 'ekn_active']:\n",
    "                    # only modify if list is not empty\n",
    "                    if self._paraminfo['KCN'].value:\n",
    "                        # loop over parameters\n",
    "                        for i in np.arange(len(paramname)):\n",
    "                            print(paramname[i]+' modified in '+self._pftfile)\n",
    "                            dset[paramname[i]][:] = self._paraminfo['KCN'].value[i]\n",
    "                \n",
    "                # for OAAT, only modify if value is not 'None'\n",
    "                elif self._paraminfo[paramname].value is not None:\n",
    "                    # params file\n",
    "                    if self._paraminfo[paramname].location == \"P\":\n",
    "                        print(paramname+' modified in '+self._pftfile)\n",
    "                        dset[paramname][:] = self._paraminfo[paramname].value\n",
    "                    # namelist\n",
    "                    elif self._paraminfo[paramname].location == \"N\":\n",
    "                        print(paramname+' modified in '+self._nlfile)\n",
    "                        with open(self._nlfile,\"a\") as file: # key is using \"a\" for append option\n",
    "                            output = \"%s=%s\\n\" % (paramname, self._paraminfo[paramname].value) #round??\n",
    "                            file.write(output)\n",
    "\n",
    "        # TO DO: LHC code for writing files\n",
    "        elif sampling_protocol == \"LHC\":\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # need to \"close\" netcdf file to write out\n",
    "        dset.close() \n",
    "        \n",
    "    def __repr__(self):\n",
    "        i = int(self._name)\n",
    "        return \"Ensemble member %s\" % (str(i+1), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: add these or other unit tests to Member class itself\n",
    "# Check every time the code updates, or adding new functionality\n",
    "\n",
    "# testing out the class/dictionary functionality\n",
    "member_test_dict = {\"M1\": Member(\"0\", paraminfo=test_dict),\n",
    "             \"M2\": Member(\"1\", paraminfo=test_dict),\n",
    "             \"M3\": Member(\"2\", paraminfo=None),\n",
    "             \"M4\": Member(\"3\", paraminfo=None)\n",
    "            }\n",
    "\n",
    "# example of adding a new member\n",
    "member_test_dict[\"new_member\"] = Member(\"new_member\", paraminfo=test_dict)\n",
    "\n",
    "# example of setting the name\n",
    "member_test_dict[\"new_member\"].name = \"4\"\n",
    "\n",
    "# look at the test dictionary\n",
    "for key in member_test_dict:\n",
    "    print(member_test_dict[key])\n",
    "    \n",
    "# look at a member's paraminfo in the test dictionary\n",
    "member_test_dict['M1'].paraminfo\n",
    "\n",
    "# look at a member's paraminfo for a specific parameter\n",
    "member_test_dict['M1'].paraminfo['P1']\n",
    "\n",
    "# get the list of parameter names\n",
    "member_test_dict['M1'].get_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a class for organizing the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(object):\n",
    "    \"\"\"\n",
    "    Stores and works with a bunch of Members.\n",
    "    \"\"\"\n",
    "    \n",
    "    # assign the basepftfile\n",
    "    #_basepftfile = \"../basecase/clm5_params.c200717.nc\"\n",
    "    _basepftfile='/glade/p/cgd/tss/people/oleson/modify_param/ctsm51_params.c210217_kwo.c210222.nc'\n",
    "    \n",
    "    # here using an example lnd_in file to pull in default namelist values\n",
    "    # could also parse the namelist defaults file, see: https://github.com/ESCOMP/CTSM/blob/e2b9745d81ed5cb7cd7f5d6098edf506a4956335/bld/namelist_files/namelist_defaults_ctsm.xml\n",
    "    #_thedir = '/glade/work/djk2120/ctsm_hardcode_co/cime/scripts/clm50c6_ctsmhardcodep_2deg_GSWP3V1_Sparse250_2000/CaseDocs/'\n",
    "    _thedir = '/glade/work/oleson/lmbirch_wkattge.n01_ctsm5.1.dev006/cime/scripts/clm51_lmbirchwkattgen01ctsm51d006_2deg_GSWP3V1_PPE_1850pAD/CaseDocs/'\n",
    "    _thefil = 'lnd_in'\n",
    "    _lndin = _thedir+_thefil\n",
    "    \n",
    "    def __init__(self, csvfile, sampling_protocol):\n",
    "        self._sampling_protocol = sampling_protocol\n",
    "        \n",
    "        print(\"Reading in data from spreadsheet...\",end=\"\")\n",
    "        \n",
    "        # read in csv data, filtering by the \"include\" column\n",
    "        data = pd.read_csv(csvfile,header=0,skiprows=[1]) # modify read_csv to account for header spanning 2 rows\n",
    "        included = data['test'] == 1\n",
    "        params_full = data.loc[included,['name','location','min','max','flag','pft_mins','pft_maxs']]\n",
    "\n",
    "        # reset indexing and get rid of excel row number\n",
    "        params = params_full.reset_index(drop=True)\n",
    "        \n",
    "        print(\"Done\")\n",
    "        \n",
    "        print(\"Creating dictionary of parameter information and reading default values...\",end=\"\")\n",
    "        \n",
    "        # declare a dictionary to store parameter information\n",
    "        self._params_dict = {}\n",
    "        \n",
    "        # read in default pftfile\n",
    "        def_params = xr.open_dataset(self._basepftfile)  \n",
    "        \n",
    "        # assigning the default values\n",
    "        # loop over parameters grabbing name, location, and flags\n",
    "        for name,loc,flag in zip(params['name'],params['location'],params['flag']):      \n",
    "            \n",
    "            # check for flags\n",
    "            # NOTE: this assumes all flagged parameters are loc=P (true for now)\n",
    "            if pd.notnull(flag):\n",
    "                # check to see if a params_dict entry has been created with flag label\n",
    "                if flag in self._params_dict.keys():\n",
    "                    # if it has already been created, append next parameter name and default value\n",
    "                    self._params_dict[flag].name.append(name)\n",
    "                    x = def_params[name].values\n",
    "                    self._params_dict[flag].default.append(x) \n",
    "                else:\n",
    "                    # if it hasn't been created, initialize the ParamInfo with placeholder lists\n",
    "                    x = def_params[name].values\n",
    "                    self._params_dict[flag] = ParamInfo(name=[name], loc=loc, defval=[x], minval=[], maxval=[], value=[])\n",
    "            \n",
    "            \n",
    "            # select parameters located in the params file\n",
    "            elif loc=='P':\n",
    "                # getting parameter dims (i.e., checking for segment variation)\n",
    "                dims = len(def_params[name].values.shape)\n",
    "                if dims<2:\n",
    "                    # no segment variation\n",
    "                    x = def_params[name].values\n",
    "                else:\n",
    "                    # segment variation: ck,kmax,psi50,rootprof_beta\n",
    "                    # assumes the same values are applied across segments\n",
    "                    # TO DO: check this assumption, appears not true for rootprof_beta\n",
    "                    x = def_params[name][0,:].values\n",
    "                self._params_dict[name] = ParamInfo(name, defval=x, loc='P')\n",
    "            \n",
    "            # select namelist parameters\n",
    "            elif loc=='N':\n",
    "                # build a command to search lnd_in file for the parameter by name and put output in a tmp file\n",
    "                cmd = 'grep '+name+' '+self._lndin+' > tmp.txt'\n",
    "                ret = os.system(cmd)\n",
    "                # checking for nonzero return code, meaning parameter is not found\n",
    "                if ret != 0:\n",
    "                    # TO DO: will need to address these special cases\n",
    "                    print(name+' not found')\n",
    "                else:\n",
    "                    f = open('tmp.txt', 'r')\n",
    "                    # parse the value from the parameter name\n",
    "                    tmp = f.read().split()[2]\n",
    "                    f.close()\n",
    "                    # cases where scientific notation is specified by a \"d\"\n",
    "                    if 'd' in tmp:\n",
    "                        tmp = tmp.split('d')\n",
    "                        x = float(tmp[0])*10**float(tmp[1])\n",
    "                    else:\n",
    "                        x = float(tmp)\n",
    "                    self._params_dict[name] = ParamInfo(name, defval=x, loc='N')\n",
    "        \n",
    "        # count entries in params_dict as number of parameters (accounts for parameter dependencies)\n",
    "        self._nparam = len(self._params_dict)\n",
    "        \n",
    "        print(\"Done\")\n",
    "        \n",
    "        print(\"Assigning min and max values...\",end=\"\")\n",
    "        \n",
    "        # assigning min and max values\n",
    "        if sampling_protocol == 'OAAT':\n",
    "            for name,minv,maxv,pftmin,pftmax,flag in zip(params['name'],params['min'],params['max'],params['pft_mins'],params['pft_maxs'],params['flag']): \n",
    "            #for i in range(self._nparam):\n",
    "                \n",
    "                # check for flags\n",
    "                if pd.notnull(flag):\n",
    "                    # check for \"XXpercent\" perturb from default\n",
    "                    if \"percent\" in minv and \"percent\" in maxv: # assumes \"percent\" is written in both min and max cells\n",
    "                        # hack for KCN flag - need to keep track parameter order for the default indexing\n",
    "                        # only want to do this for loop ONCE (need to fix this logic) so only execute if min/max lists are currently empty\n",
    "                        if self._params_dict[flag].min == [] and self._params_dict[flag].max == []:\n",
    "                            for i,p in enumerate(self._params_dict[flag].name):\n",
    "                                percent_perturb_min = float(minv.split(\"percent\")[0])\n",
    "                                percent_perturb_max = float(maxv.split(\"percent\")[0])\n",
    "                                percent_min_values = self._params_dict[flag].default[i]*(1 - percent_perturb_min/100)\n",
    "                                percent_max_values = self._params_dict[flag].default[i]*(1 + percent_perturb_max/100)\n",
    "                                self._params_dict[flag].min.append(percent_min_values)\n",
    "                                self._params_dict[flag].max.append(percent_max_values)\n",
    "                    else:\n",
    "                        #self._params_dict['CWD'].min.append(params['min'].values[i])\n",
    "                        #self._params_dict['CWD'].max.append(params['max'].values[i])\n",
    "                        self._params_dict[flag].min.append(minv)\n",
    "                        self._params_dict[flag].max.append(maxv)\n",
    "                \n",
    "                # check for pft variation\n",
    "                #elif params['min'].values[i]=='pft': # assumes \"pft\" is written in both min and max cells\n",
    "                elif minv=='pft' and maxv=='pft':    \n",
    "                    #self._params_dict[params['name'].values[i]].min = np.fromstring(params['pft_mins'][i],dtype='float',sep=',')\n",
    "                    #self._params_dict[params['name'].values[i]].max = np.fromstring(params['pft_maxs'][i],dtype='float',sep=',')\n",
    "                    self._params_dict[name].min = np.fromstring(pftmin, dtype='float', sep=',')\n",
    "                    self._params_dict[name].max = np.fromstring(pftmax, dtype='float', sep=',')\n",
    "                \n",
    "                # check for \"XXpercent\" perturb from default\n",
    "                #elif \"percent\" in params['min'].values[i]: # assumes \"percent\" is written in both min and max cells\n",
    "                elif \"percent\" in minv and \"percent\" in maxv: # assumes \"percent\" is written in both min and max cells\n",
    "                    #percent_perturb_min = float(params['min'].values[i].split(\"percent\")[0])\n",
    "                    #percent_perturb_max = float(params['max'].values[i].split(\"percent\")[0])\n",
    "                    #percent_min_values = self._params_dict[params['name'].values[i]].default*(1 - percent_perturb_min/100)\n",
    "                    #percent_max_values = self._params_dict[params['name'].values[i]].default*(1 + percent_perturb_max/100)            \n",
    "                    #self._params_dict[params['name'].values[i]].min = percent_min_values\n",
    "                    #self._params_dict[params['name'].values[i]].max = percent_max_values        \n",
    "                    percent_perturb_min = float(minv.split(\"percent\")[0])\n",
    "                    percent_perturb_max = float(maxv.split(\"percent\")[0])\n",
    "                    percent_min_values = self._params_dict[name].default*(1 - percent_perturb_min/100)\n",
    "                    percent_max_values = self._params_dict[name].default*(1 + percent_perturb_max/100)\n",
    "                    self._params_dict[name].min = percent_min_values\n",
    "                    self._params_dict[name].max = percent_max_values\n",
    "                \n",
    "                else:\n",
    "                    # assign min/max values directly\n",
    "                    #self._params_dict[params['name'].values[i]].min = params['min'].values[i]\n",
    "                    #self._params_dict[params['name'].values[i]].max = params['max'].values[i]\n",
    "                    self._params_dict[name].min = minv\n",
    "                    self._params_dict[name].max = maxv\n",
    "        \n",
    "        elif sampling_protocol == 'LHC':\n",
    "            # TO DO: assign LHC min/maxes\n",
    "            pass\n",
    "        \n",
    "        print(\"Done\")\n",
    "        \n",
    "        # declare a dictionary to store member information\n",
    "        self._members = {}\n",
    "        \n",
    "        # set the number of ensemble members\n",
    "        if sampling_protocol == 'OAAT':\n",
    "            # number of samples is twice the number of parameter entries in param_dict (min and max perturbations)\n",
    "            nsamp = 2*self._nparam\n",
    "        elif sampling_protocol == 'LHC':\n",
    "            # define sample size for LHC (user-specified)\n",
    "            nsamp = 10\n",
    "        \n",
    "        print(\"Creating ensemble with \"+str(nsamp)+\" members...\",end=\"\")\n",
    "        \n",
    "        # create the ensemble members\n",
    "        # need to \"deepcopy\" the dictionary for each member so they can be modified independently\n",
    "        for i in range(nsamp):\n",
    "            self._members[i] = Member(str(i), copy.deepcopy(self._params_dict))\n",
    "        \n",
    "        # loop over members and calculate parameter values for each member                \n",
    "        # TO DO: OAAT ONLY - NEED TO ADD LHC CODE\n",
    "        doneparams = []\n",
    "        for member in self._members:\n",
    "            #for paramname in self._members[member].get_names():\n",
    "            for paramname in self._params_dict.keys():\n",
    "                # check if this parameter has already been assigned\n",
    "                if paramname in doneparams:\n",
    "                    continue\n",
    "                # check if this is a min or max perturbation\n",
    "                if int(self._members[member].name)%2 == 0:\n",
    "                    # min values\n",
    "                    self._members[member].paraminfo[paramname].value = self._members[member].paraminfo[paramname].min\n",
    "                    break\n",
    "                else:\n",
    "                    # max values\n",
    "                    self._members[member].paraminfo[paramname].value = self._members[member].paraminfo[paramname].max\n",
    "                    \n",
    "                    # parameter is \"done\" after creating min/max ensemble members in sequence\n",
    "                    doneparams.append(paramname)\n",
    "                    break\n",
    "        \n",
    "        print(\"Done\")\n",
    "        \n",
    "    @property\n",
    "    def params(self):\n",
    "        return self._params_dict\n",
    "    \n",
    "    @property\n",
    "    def members(self):\n",
    "        return self._members\n",
    "    \n",
    "    def output_files(self):\n",
    "        \"\"\"\n",
    "        Loop over members in the ensemble and call the write function.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Writing files to disk for each member...\")\n",
    "        \n",
    "        for member in self._members:\n",
    "            self._members[member].write(self._sampling_protocol)\n",
    "    \n",
    "        print(\"Done\")\n",
    "    \n",
    "    def save_psets(self, ensemble_name):\n",
    "        \"\"\"\n",
    "        Save the parameter values for the ensemble.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Writing out parameter info for the ensemble...\",end=\"\")\n",
    "        \n",
    "        # build the file name with the prefix (ensemble type)\n",
    "        psetsfile = \"../parameter_sets/\"+self._sampling_protocol+\"_\"+ensemble_name+\".txt\"\n",
    "        #psetsfile = \"../parameter_sets/\"+self._sampling_protocol+\"_\"+ensemble_name+\".json\"\n",
    "        \n",
    "        # TO DO: figure out how to organize pset info\n",
    "\n",
    "        # Currently this writes a very long text file, but all the information is there\n",
    "        # Question is for reading this info back in for analysis, what is the best way to store the pset info\n",
    "        with open(psetsfile, 'w') as fp:\n",
    "            for member in self._members:\n",
    "                fp.write(str(self._members[member]) + '\\n')\n",
    "                #for paramname in self._members[member].get_names():\n",
    "                for paramname in self._params_dict.keys():\n",
    "                    fp.write(str(self._members[member].paraminfo[paramname]) + '\\n')\n",
    "                    fp.write('\\n')\n",
    "                fp.write('\\n')\n",
    "        \n",
    "        print(\"Done\")\n",
    "        \n",
    "        # Another option: Create a new dictionary converting numpy arrays to lists so they are serializable with JSON\n",
    "        # But then they are not readable as numpy arrays after saving out the JSON\n",
    "        \n",
    "        # This JSON hack method doesn't work because self._members is a dictionary of dictionaries\n",
    "        #dumped = json.dumps(self._members, cls=NumpyEncoder)\n",
    "        #with open(psetsfile, 'w') as fp:\n",
    "            #json.dump(dumped, fp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data from spreadsheet...Done\n",
      "Creating dictionary of parameter information and reading default values...Done\n",
      "Assigning min and max values...Done\n",
      "Creating ensemble with 34 members...Done\n"
     ]
    }
   ],
   "source": [
    "# Using this Ensemble class with the input csv file\n",
    "newEns = Ensemble('params.csv', 'OAAT')\n",
    "\n",
    "# get the params_dict - not associated with a specific member (none of the \"value\" entries are set)\n",
    "#newEns.params\n",
    "\n",
    "# get parameter names for a specific ensemble member\n",
    "#newEns.members[0].get_names()\n",
    "\n",
    "# example of how to print member/param info\n",
    "#for member in newEns.members:\n",
    "#    print(newEns.members[member])\n",
    "#    print(newEns.members[member].paraminfo)\n",
    "    \n",
    "# example of how to print paraminfo for a given member\n",
    "#newEns.members[0].paraminfo\n",
    "\n",
    "# example of how to print paraminfo of a specific parameter for a given member\n",
    "#newEns.members[0].paraminfo['fff']\n",
    "\n",
    "# example of how to print paraminfo of a specific parameter for all members\n",
    "#for member in newEns.members:\n",
    "#    print(newEns.members[member].paraminfo['fff'])\n",
    "\n",
    "# example of how to print the \"value\" info of a specific parameter for all members\n",
    "#for member in newEns.members:\n",
    "#    print(newEns.members[member].paraminfo['fff'].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taulnir\n",
      "dleaf\n",
      "tkd_sand\n",
      "bsw_sf\n",
      "n_melt_coef\n",
      "medlynslope\n",
      "jmaxb1\n",
      "kmax\n",
      "dbh\n",
      "grperc\n",
      "FUN_fracfixers\n",
      "froot_leaf\n",
      "leaf_long\n",
      "tau_cwd\n",
      "k_nitr_max_perday\n",
      "cli_scale\n",
      "vcmaxha\n"
     ]
    }
   ],
   "source": [
    "# print list of parameters \n",
    "for param in newEns.members[0].paraminfo:\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check the \"values\" across ensemble members\n",
    "for member in newEns.members:\n",
    "    print(newEns.members[member])\n",
    "    for param in newEns.members[member].paraminfo:\n",
    "        print(param)\n",
    "        print(newEns.members[member].paraminfo[param].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing files to disk for each member...\n",
      "taulnir modified in ../paramfiles/OAAT0001.nc\n",
      "taulnir modified in ../paramfiles/OAAT0002.nc\n",
      "dleaf modified in ../paramfiles/OAAT0003.nc\n",
      "dleaf modified in ../paramfiles/OAAT0004.nc\n",
      "tkd_sand modified in ../paramfiles/OAAT0005.nc\n",
      "tkd_sand modified in ../paramfiles/OAAT0006.nc\n",
      "bsw_sf modified in ../paramfiles/OAAT0007.nc\n",
      "bsw_sf modified in ../paramfiles/OAAT0008.nc\n",
      "n_melt_coef modified in ../paramfiles/OAAT0009.nc\n",
      "n_melt_coef modified in ../paramfiles/OAAT0010.nc\n",
      "medlynslope modified in ../paramfiles/OAAT0011.nc\n",
      "medlynslope modified in ../paramfiles/OAAT0012.nc\n",
      "jmaxb1 modified in ../namelist_mods/OAAT0013.txt\n",
      "jmaxb1 modified in ../namelist_mods/OAAT0014.txt\n",
      "kmax modified in ../paramfiles/OAAT0015.nc\n",
      "kmax modified in ../paramfiles/OAAT0016.nc\n",
      "dbh modified in ../paramfiles/OAAT0017.nc\n",
      "dbh modified in ../paramfiles/OAAT0018.nc\n",
      "grperc modified in ../paramfiles/OAAT0019.nc\n",
      "grperc modified in ../paramfiles/OAAT0020.nc\n",
      "FUN_fracfixers modified in ../paramfiles/OAAT0021.nc\n",
      "FUN_fracfixers modified in ../paramfiles/OAAT0022.nc\n",
      "froot_leaf modified in ../paramfiles/OAAT0023.nc\n",
      "froot_leaf modified in ../paramfiles/OAAT0024.nc\n",
      "leaf_long modified in ../paramfiles/OAAT0025.nc\n",
      "leaf_long modified in ../paramfiles/OAAT0026.nc\n",
      "tau_cwd modified in ../paramfiles/OAAT0027.nc\n",
      "tau_cwd modified in ../paramfiles/OAAT0028.nc\n",
      "k_nitr_max_perday modified in ../paramfiles/OAAT0029.nc\n",
      "k_nitr_max_perday modified in ../paramfiles/OAAT0030.nc\n",
      "cli_scale modified in ../namelist_mods/OAAT0031.txt\n",
      "cli_scale modified in ../namelist_mods/OAAT0032.txt\n",
      "vcmaxha modified in ../paramfiles/OAAT0033.nc\n",
      "vcmaxha modified in ../paramfiles/OAAT0034.nc\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Writing out param and nl files\n",
    "newEns.output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing out parameter info for the ensemble...Done\n"
     ]
    }
   ],
   "source": [
    "# Testing writing out ensemble info, need to provide a name for the Ensemble\n",
    "#newEns.save_psets('test0001') # 148 parameters on 8/25/20\n",
    "#newEns.save_psets('test0002') # 178 parameters on 10/9/20\n",
    "#newEns.save_psets('test0003') # 183 parameters on 10/9/20\n",
    "#newEns.save_psets('test0004') # 192 parameters on 10/14/20\n",
    "#newEns.save_psets('test0005') # testing CWD dependency on 10/21/20\n",
    "#newEns.save_psets('test0006') # testing all parameter dependencies on 10/21/20\n",
    "#newEns.save_psets('test0007') # 192 parameters including dependencies on 10/22/20\n",
    "#newEns.save_psets('test_miniens_20201102') # testing mini-ensemble (medlynslope and slatop) on 11/2/20\n",
    "#newEns.save_psets('test_miniens_20201211') # testing mini-ensemble (sand_pf and clay_pf) on 12/11/20\n",
    "#newEns.save_psets('test_bhs') # testing biomass heat storage params on 2/4/21\n",
    "newEns.save_psets('test_miniens_20210222') # testing mini-ensemble (17 params) on 2/22/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some notes on OAAT parameter testing:\n",
    "* don't currently have checks to see if min or max are equivalent to default value (in that case, don't change params files / don't make a namelist mod?) - precision/round-off errors could be important here\n",
    "* `rootprof_beta` has slighty different default values across variants, code currently assumes the same values applied across these secondary dims\n",
    "* for parameters that vary with PFT but only a single value is specified in the spreadsheet, that value will propogate across all PFTs (including index 0 = non-vegetated)\n",
    "* all current parameter dependencies (e.g., \"these three terms need to add up to 1\") are working, but solution could be cleaner and more universal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (work in progress) Define a class for converting numpy arrays to be JSON serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" \n",
    "    Special json encoder for numpy types\n",
    "    \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: integrate this code above for LHC option\n",
    " * careful, each time you run LHC you get a new random draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sampling_protocol == 'LHC':\n",
    "    # define sample size (number of ensemble members)\n",
    "    nsamp = 10\n",
    "\n",
    "    # Generate the latin hypercube sample\n",
    "    lhd = lhs(nparam, samples=int(nsamp))\n",
    "    # lhd is a 2D array indexed by ensemble member x parameter\n",
    "    \n",
    "    # figure out how many pft-dependent params there are in this sample\n",
    "    npftparam = sum(params['min']=='pft')\n",
    "    \n",
    "    if npftparam>0:\n",
    "        # get dataframe index of first pft param\n",
    "        pftfirstind = params.index[params['min']=='pft'][0]\n",
    "        \n",
    "        # get number of pfts\n",
    "        npft = len(np.fromstring(params['pft_mins'][pftfirstind],dtype='float',sep=','))\n",
    "        \n",
    "        # set up numpy array to store pft-specific values\n",
    "        pft_array = np.nan*np.ones([npftparam,npft,nsamp])\n",
    "        \n",
    "        for j in range(npftparam):\n",
    "            # get the index for the current pft param\n",
    "            pftind = params.index[params['min']=='pft'][j]\n",
    "            \n",
    "            # get min values\n",
    "            min_pft_array = np.fromstring(params['pft_mins'][pftind],dtype='float',sep=',')\n",
    "            # max values\n",
    "            max_pft_array = np.fromstring(params['pft_maxs'][pftind],dtype='float',sep=',')\n",
    "            \n",
    "            # loop over samples and calculate parameter values for each pft\n",
    "            for i in range(nsamp):\n",
    "                pft_array[j,:,i] = (max_pft_array - min_pft_array)*lhd[i,pftind] + min_pft_array\n",
    "                # can't store pft_array as a pandas dataframe because it's 3D\n",
    "                # unless there is some alternate way to store this data?\n",
    "    \n",
    "    # initialize min/max arrays - for params without pft-variation\n",
    "    min_array = np.nan*np.ones(nparam)\n",
    "    max_array = np.nan*np.ones(nparam)\n",
    "    \n",
    "    # generate arrays with min and max values\n",
    "    for i in range(nparam):\n",
    "        if params['min'].values[i]=='pft':\n",
    "            # TO DO: what's a good placeholder, to denote need to reference pft_array?\n",
    "            # numpy doesn't like assigning a string to an existing array of floats\n",
    "            # for now, just print a message\n",
    "            print('skipping '+params['name'].values[i]+'...this parameter varies with PFT')\n",
    "            \n",
    "            # Numpy doesn't like assigning an array to a single index in an existing array\n",
    "            # The problem is still that I'm declaring min_array before trying to assign values\n",
    "            # If I could build it all at once, numpy would allow for nested arrays\n",
    "            #min_array[i] = np.fromstring(params['pft_mins'].values[i],dtype='float',sep=',')\n",
    "            #max_array[i] = np.fromstring(params['pft_maxs'].values[i],dtype='float',sep=',')\n",
    "        else:\n",
    "            # assign min/max values\n",
    "            min_array[i] = float(params['min'].values[i])\n",
    "            max_array[i] = float(params['max'].values[i])\n",
    "            \n",
    "    # calculate parameter values; skip pft params (NaNs in min/max arrays)\n",
    "    param_array = (max_array - min_array)*lhd + min_array\n",
    "\n",
    "# store psets in a pandas dataframe\n",
    "#psets = pd.DataFrame(data=param_array, index=None, columns=params['name'])\n",
    "#psets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda-analysis)",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
